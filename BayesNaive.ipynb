{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes ingenuo"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Para el algoritmo de Bayes ingenuo o Bays naive necesitamos un conjunto supervisado S que contenga frases y una etiqueta correspondiete a la clase que corresponde ese etiquetado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Amo esa cosa', 'positivo'), ('Me gusta el chocolate', 'positivo'), ('Odio esa cosa', 'negativo'), ('Amo mi trabajo', 'positivo'), ('Detesto tu camisa', 'negativo')]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "from operator import itemgetter\n",
    "\n",
    "S = [('Amo esa cosa','positivo'),('Me gusta el chocolate','positivo'),('Odio esa cosa','negativo'),('Amo mi trabajo','positivo'),('Detesto tu camisa','negativo')]\n",
    "   \n",
    "print S\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ahora definamos las funciones que nos permitirán guardadr el vocabulario y las frases como bolsa de palabras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, 2], [3, 4, 5, 6], [7, 1, 2], [0, 8, 9], [10, 11, 12]]\n"
     ]
    }
   ],
   "source": [
    "def vocab():\n",
    "    dicc = defaultdict()\n",
    "    dicc.default_factory = lambda: len(dicc)\n",
    "    return dicc\n",
    "\n",
    "def BoW(corpus,vocab):\n",
    "    for w in corpus:\n",
    "        yield[vocab[w_i] for w_i in w.lower().split()]\n",
    "        \n",
    "words = vocab()\n",
    "frases = list(BoW( [s[0] for s in S],words ))\n",
    "\n",
    "print frases"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ahora, como en el algoritmo requerimos de la probabilidad de la clase, tomaremos la frecuencia de cada clase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'positivo': 3, 'negativo': 2})\n"
     ]
    }
   ],
   "source": [
    "frec_clase = Counter([s[1] for s in S])\n",
    "\n",
    "print frec_clase"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Para obtener la probabilidad usaremos un smoothing de Lidstone, por tanto definiremos esta función de probabilidad y la aplicaremos, por el momento, a las clases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def p(f_conj,f_cond,l=0.01):\n",
    "    return (f_conj+l)/(f_cond+l*len(words))\n",
    "\n",
    "P_c = np.zeros(len(frec_clase))\n",
    "for i,(c,f) in enumerate(frec_clase.iteritems()):\n",
    "    P_c[i] = p(f,len(S))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "De esta forma, podemos ver que cada clase tiene asignado un id. Por ejemplo, la clase 0 será la clase 'positivo' y la clase 1 la clase 'negativo':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.586744639376\n",
      "0.391812865497\n"
     ]
    }
   ],
   "source": [
    "print P_c[0]\n",
    "print P_c[1]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ahora, necesitamos definir el conjunto de entrenamiento a partir de las palabras que contiene cada clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_corpus = defaultdict(list)\n",
    "for s in S:\n",
    "    for word in s[0].lower().split():\n",
    "        train_corpus[s[1]].append(word)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "La clase 'positivo' cuenta con las palabras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amo', 'esa', 'cosa', 'me', 'gusta', 'el', 'chocolate', 'amo', 'mi', 'trabajo']\n"
     ]
    }
   ],
   "source": [
    "print train_corpus['positivo']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Para finalizar el proceso de aprendizaje aprenderemos una matriz donde se contenga el número de las palabras por el número de las clases, de tal forma que cada entrada contenga la probabilidad con smoothing) correspondiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = np.zeros((len(words),len(train_corpus)))\n",
    "\n",
    "for i,(clase,w) in enumerate(train_corpus.iteritems()):\n",
    "    frecs = Counter(w)\n",
    "    for word in words:\n",
    "        if word in w:\n",
    "            A[words[word],i] =  p(frecs[word],frec_clase[clase])\n",
    "        else:\n",
    "            A[words[word],i] = p(0,frec_clase[clase])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Así, nuestro modelo de aprendizaje estará formado por las probabilidades de las clases y por las probabilidades de las palabras dadas las clases; es decir, por el vector P_c y la matriz A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidad de clases:  [ 0.58674464  0.39181287]\n",
      "Matriz de probabilidades:  \n",
      "[[ 0.64217252  0.00469484]\n",
      " [ 0.32268371  0.4741784 ]\n",
      " [ 0.32268371  0.4741784 ]\n",
      " [ 0.32268371  0.00469484]\n",
      " [ 0.32268371  0.00469484]\n",
      " [ 0.32268371  0.00469484]\n",
      " [ 0.32268371  0.00469484]\n",
      " [ 0.00319489  0.4741784 ]\n",
      " [ 0.32268371  0.00469484]\n",
      " [ 0.32268371  0.00469484]\n",
      " [ 0.00319489  0.4741784 ]\n",
      " [ 0.00319489  0.4741784 ]\n",
      " [ 0.00319489  0.4741784 ]]\n"
     ]
    }
   ],
   "source": [
    "print 'Probabilidad de clases: ',P_c\n",
    "print 'Matriz de probabilidades: ','\\n', A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proceso de evaluación"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Para la evaluación, definiremos una función que nos devuelva la probabilidad de una clase dado una cadena de evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prob_clase(sent,clase_id):\n",
    "    prob = 1.0\n",
    "    for word in sent.lower().split():\n",
    "        try:\n",
    "            prob *= A[words[word],clase_id]\n",
    "        except:\n",
    "            prob *= 1.0\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Si tomamos una frase como \"odio la vida\", aunque el aprendizaje nunca haya observado la palabra 'vida' podrá calcular la probabilidad de una clase. Por ejemplo, la clase 'negativo' equivalente al id 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.474178403756\n"
     ]
    }
   ],
   "source": [
    "eval_sent = 'odio la vida'\n",
    "print prob_clase(eval_sent,1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Finalmente, definiremos una función que devuelva la clase que maximice la probabilidad dada la frase de evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(sent):\n",
    "    clases = {}\n",
    "    for i,c in enumerate(frec_clase): \n",
    "        clases[c] = prob_clase(sent,i)\n",
    "    return max(clases.iteritems(), key=itemgetter(1))[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "De tal forma que si tomamos la frase anterior nos devolverá la clase de predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negativo\n"
     ]
    }
   ],
   "source": [
    "print predict(eval_sent)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tomemos ahora una frase como \"Amo la forma en que me miras\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positivo\n"
     ]
    }
   ],
   "source": [
    "print predict('Amo la forma en que me miras')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Las predicciones parecen acordes con las del ser humao. Sin embargo, para que el modelo funcione mejor se requiere de un corpus de entrenamiento más grande, además de técnicas como el uso de n-gramas, implementación de smoothin lineal, etc. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
